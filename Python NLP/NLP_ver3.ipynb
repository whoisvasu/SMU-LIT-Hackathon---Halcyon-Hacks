{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2cd1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"['Civil claims']\", \"['Incapacity and inheritance']\",\n",
       "       \"['Personal legal procedures']\", \"['Property and Housing']\",\n",
       "       \"['Family']\", nan,\n",
       "       \"['Contentious Commercial Corporate Disputes ']\", \"['Crime']\",\n",
       "       \"['TMT Data Protection and Privacy']\",\n",
       "       \"['Non Contentious Commercial Corporate Advisory ']\",\n",
       "       \"['Intellectual Property']\", \"['Syariah Law']\"], dtype=object)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as py\n",
    "df = pd.read_csv(\"finaldataset.csv\")\n",
    "\n",
    "df['Tag1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bb756c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160e86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e38af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256345da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1ca71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9e08e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f31462d56c8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmultilabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultiLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultilabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tag3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ex' is not defined"
     ]
    }
   ],
   "source": [
    "multilabel = MultiLabelBinarizer()\n",
    "y = multilabel.fit_transform(ex['Tag3'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf65f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60080eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed48b337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dc3b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c2f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cd05e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Case'].replace('', py.nan, inplace=True)\n",
    "df.dropna(subset=['Case'], inplace=True)\n",
    "df['Case'].isnull().sum()\n",
    "\n",
    "df['Tag1'].isnull().sum()\n",
    "df.dropna(subset=['Tag1'], inplace=True)\n",
    "df['Tag1'].isnull().sum()\n",
    "df = df[['Case','Tag1']]\n",
    "df['Tag1'] = df['Tag1'].astype(str)\n",
    "df['Tag1'].unique()\n",
    "import ast\n",
    "df['Tag1'] = df['Tag1'].apply(lambda x: ast.literal_eval(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b3b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "## Cleaning Text ####\n",
    "#####################\n",
    "\n",
    "import re\n",
    "def casecleaner(casetext):\n",
    "    casetext = re.sub(\"[?,.®'&$’\\\"\\-()]\"  , \"\", str(casetext)) #remove special characters\n",
    "    casetext = re.sub(\"�<[a-z]+/?>\", \"\", str(casetext)) #remove html codes\n",
    "    casetext = re.sub(\"[^\\x00-\\x7F]+\", \"\", str(casetext))\n",
    "    casetext = casetext.strip() #remove leading and trailing spaces\n",
    "    casetext = casetext.lower() #change to lower case\n",
    "    return casetext\n",
    "\n",
    "df['Case'] = df['Case'].apply(casecleaner)\n",
    "df.head()\n",
    "\n",
    "##################################################\n",
    "#### Tokenization, Stemming, Stopword Removal ####\n",
    "##################################################\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenizer=RegexpTokenizer(r'\\w+')\n",
    "en_stopwords=set(stopwords.words('english'))\n",
    "ps=PorterStemmer()\n",
    "\n",
    "def getStemmedReview(review):\n",
    "    tokens=tokenizer.tokenize(review)\n",
    "    new_tokens=[token for token in tokens if token not in  en_stopwords]\n",
    "    stemmed_tokens=[ps.stem(token) for token in new_tokens]\n",
    "    clean_review=' '.join(stemmed_tokens)\n",
    "    return clean_review\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacb38b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339cc49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel = MultiLabelBinarizer()\n",
    "y = multilabel.fit_transform(df['Tag1'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8003c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b912efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y, columns = multilabel.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ced39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word', max_features=1000, ngram_range=(1,3), stop_words='english')\n",
    "X = tfidf.fit_transform(df['Case'])\n",
    "X\n",
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd92a755",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2528ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8177c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_score(y_true, y_pred):\n",
    "    jaccard = py.minimum(y_true, y_pred).sum(axis = 1)/py.maximum(y_true, y_pred).sum(axis = 1)\n",
    "    return jaccard.mean()*100\n",
    "\n",
    "def print_score(y_pred, clf):\n",
    "    print('clf:', clf.__class__.__name__)\n",
    "    print('Jaccard score: {}'.format(j_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier()\n",
    "lr = LogisticRegression(solver = 'lbfgs')\n",
    "svc = LinearSVC()\n",
    "nbc = naive_bayes.MultinomialNB()\n",
    "\n",
    "clf = OneVsRestClassifier(sgd)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print_score(y_pred, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33059e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for classifier in [sgd, lr, svc, nbc]:\n",
    "    clf2 = OneVsRestClassifier(classifier)\n",
    "    clf2.fit(X_train, y_train)\n",
    "    y_pred = clf2.predict(X_test)\n",
    "    print_score(y_pred, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca6616",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = ['I have this tenant that rents on my property, a single family house with a back house, she has been renting for 15 years, and we have barely increased her rent for the past 3 years by $50 per year (Yes i know i should have increased it since the beginning), now we are in need of using that section of the home for personal use, but now with the eviction moratorium in California, am i able to evict her out my property with no fault cause? This is also with a non-contract agreement, this was done verbally.']\n",
    "xt = tfidf.transform(test_input)\n",
    "clf.predict(xt)\n",
    "ab = multilabel.inverse_transform(clf.predict(xt))\n",
    "finalstring = ab[0][0]\n",
    "finalstring\n",
    "print(clf.predict(xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8e76b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(clf, 'model.pkl')\n",
    "joblib.dump(tfidf, 'tfidf.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
